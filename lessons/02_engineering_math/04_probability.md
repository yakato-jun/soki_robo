# 確率 —「過去の観測から今を推定する道具」

---

## ガチャの確率との違い

**ゴールライン**: 高校で学んだ確率と工学の確率は使い方が違うことが分かる。

### 頻度主義とベイズ主義

確率には2つの考え方があります。

| 考え方 | 何を確率と呼ぶか | 例 |
| ------ | ---------------- | -- |
| 頻度主義（frequentist） | 繰り返したら何割起きるか（客観的な割合） | サイコロ、ガチャ |
| ベイズ主義（Bayesian） | 今どれくらい信じているか（主観的な信念の度合い） | ロボットの位置推定 |

### ガチャの確率

- 排出率1%のガチャ → 100回引けば「だいたい1回」当たる
- 確率は **事前に固定** されている
- 結果は「当たり」か「ハズレ」かの離散的な話
- これは頻度主義的な確率

### ロボットの確率

- 「ロボットは今どこにいるか？」
- センサの値が来た → 「このセンサの値が出るなら、たぶんこの辺にいるはず」
- 新しいセンサの値が来た → 「推定を更新。こっちの方が確からしい」
- 確率は **観測のたびに更新** されていく
- これはベイズ主義的な確率

ロボットは「今どれくらい信じているか」を観測のたびに更新し続ける必要があります。
だからベイズ的な考え方が自然に合います。

> **注意**: 頻度主義が使えないわけではありません。両方大事です。
> 大学では頻度主義の統計学から入ることが多いので、そこで混乱しないように。

---

## なぜ確率が必要か

**ゴールライン**: 確率がないとどうなるかが分かる。確率があると何ができるかが分かる。

### 確率なしの世界

確率を使わないと、過去のデータを加工するしかありません。

- ローパスフィルタ: ノイズを滑らかにする → **必ず遅れる**
- 移動平均: 直近N個の平均を取る → **必ず遅れる**

どんなに工夫しても、過去のデータを整えているだけなので **遅れがなくならない**。

### 観測は常に過去

ここが重要です。

センサの値を読んだ時点で、その値は **過去のもの** です。
光の速さで測っても、処理時間がある。
「現在」は、観測から見れば常に **未来** です。

### 確率ありの世界

確率があると:

1. **過去の観測から「今ここにいるはず」を推定できる**
   - モデル（物理法則）+ 過去の観測 → 現在の推定
2. **さらに未来を予測できる**
   - 現在の推定 + モデル → 未来の予測 → MPC（モデル予測制御）の土台

確率は「遅れを超える」ための道具です。

---

## 確率の道具箱

**ゴールライン**: 各概念の名前と「要するにこういうこと」が分かる。

すべて「過去の観測から今を推定する」の手段として、1本の幹から枝分かれします。

### 分散 — ばらつき = 信頼度の逆

```python
import numpy as np

data = np.array([10.1, 9.8, 10.2, 10.0, 9.9])
print(np.var(data))   # 0.02  ← ばらつき小さい = 信頼度高い

noisy = np.array([10.5, 8.2, 12.1, 7.8, 11.4])
print(np.var(noisy))  # 2.62  ← ばらつき大きい = 信頼度低い
```

- ばらつきが小さい → そのセンサの値は信頼できる
- ばらつきが大きい → そのセンサの値はあまり信頼できない
- 分散 = 信頼度の逆。これがフュージョンの重みになる

### マルコフ性 — 直前だけで十分

推定に使うのは **直前の状態だけ** で十分。全履歴は不要。

- 「今ここにいる」が分かっていれば、「1秒前にどこにいたか」から次の位置を推定できる
- 「10分前にどこにいたか」は関係ない（直前の状態が全部含んでいる）

これがあるから、ロボットは常に最新の状態だけ持っていればよく、
メモリも計算量も現実的に収まります。

### ベイズ更新 — 事前の推定 × 新しい観測の信頼度 → 事後の推定

```
事後の推定 ∝ 事前の推定 × 観測の尤もらしさ
```

1. 事前推定: 「たぶんこの辺にいるはず」（モデルから予測）
2. 観測: 「センサがこう言っている」
3. 事後推定: 両方を合わせて「ここにいる確率が一番高い」

これがカルマンフィルタの核心です。

### 尤度 — 矢印の向きが逆

- **確率**: パラメータ → データ（「この位置にいるなら、センサはこういう値を出すはず」）
- **尤度**: データ → パラメータ（「このセンサ値が出たなら、この位置にいる可能性が高い」）

矢印が逆。「確率は→、尤度は←」。これだけ覚えておけば十分。

### フュージョン — 複数センサを信頼度で混ぜる

```python
# エンコーダの推定: 位置 = 1.0m, 分散 = 0.1
# LiDARの推定: 位置 = 1.2m, 分散 = 0.05

# 分散が小さい（信頼度が高い）方に重みを寄せて混ぜる
var_enc = 0.1
var_lidar = 0.05

w_enc = (1/var_enc) / (1/var_enc + 1/var_lidar)
w_lidar = (1/var_lidar) / (1/var_enc + 1/var_lidar)

fused = w_enc * 1.0 + w_lidar * 1.2
print(f"融合結果: {fused:.2f}m")  # 1.13m（LiDAR寄り）
print(f"重み: enc={w_enc:.2f}, lidar={w_lidar:.2f}")
```

信頼度が高いセンサの値に寄る。直感的に正しいですよね。

---

## N増しと収束

**ゴールライン**: 確率で扱えるものと扱えないものの区別が分かる。

### データを増やすと収束するか

```python
# サイコロを振る回数を増やすと...
for n in [10, 100, 1000, 10000]:
    rolls = np.random.randint(1, 7, size=n)
    print(f"N={n:>5}: 平均={np.mean(rolls):.3f}")
# N=   10: 平均=3.800
# N=  100: 平均=3.510
# N= 1000: 平均=3.487
# N=10000: 平均=3.500  ← 3.5に収束
```

- データを増やして収束するもの → 確率で扱える
- 収束しないもの → 確率では扱えない（別のアプローチが要る）

### 単独の値での評価は無意味

「センサの値が10.5だった」— これだけでは何も分かりません。

- 平均が10.0で分散が0.1なら → 10.5はかなり外れた値（要注意）
- 平均が10.0で分散が10.0なら → 10.5は普通の値（気にしなくていい）

**分布の中でどう位置づけるか** が重要。値そのものではなく。

> **大学チラ見せ**: 大数の法則、中心極限定理とか。
> 「なぜ収束するのか」の理論は大学で学びます。
> ここでは「収束するかどうかで確率が使えるか判断する」が分かればOK。

---

## 大学で躓きやすいポイント

確率変数・確率密度関数の定義が抽象的です。
「確率」なのに積分が出てきて混乱します。
頻度主義の検定（p値、帰無仮説）で「何をやっているのか」が分からなくなりがちです。

「確率 = 信じている度合い」「分散 = 信頼度の逆」という直感があると、
抽象的な定義にも「ああ、これはあの直感を一般化しているのか」と繋がります。

## 今は分かってなくて当然

- ベイズの定理を式で導出すること
- 確率密度関数の積分
- 条件付き確率の計算
- 統計的検定（p値、帰無仮説）

ここでは「概念の名前と意味」だけ持っていればOKです。

---

**次のレッスン**: → #27 相補フィルタ (`03_engineering_computation/04_complementary_filter`)
